{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90053aee-70a3-40d5-ab35-61fc2d23785a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      " Student ID     0\n",
      "Math           0\n",
      "Science        0\n",
      "English        0\n",
      "Total_Score    0\n",
      "dtype: int64\n",
      "\n",
      "Updated Dataset:\n",
      "   Student ID  Math  Science  English  Total_Score  Average_Score\n",
      "0       S001    78       85       74          237           79.0\n",
      "1       S002    56       62       59          177           59.0\n",
      "2       S003    90       88       92          270           90.0\n",
      "3       S004    70       65       72          207           69.0\n",
      "4       S005    82       79       85          246           82.0\n",
      "Training samples: 8, Testing samples: 2\n",
      "Optimized RMSE: 5.40\n",
      "Optimized R² Score: 0.09\n",
      "\n",
      "Missing Values:\n",
      " Transaction ID    0\n",
      "Amount            0\n",
      "Type              0\n",
      "Is Fraud          0\n",
      "dtype: int64\n",
      "Training samples: 8, Testing samples: 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         1\n",
      "           1       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Recommendations:\n",
      "- Try more advanced feature engineering (e.g., transaction frequency, time-based features).\n",
      "- Use ensemble methods like Random Forest or boosting for better accuracy.\n",
      "- Address class imbalance if present using SMOTE or class weights.\n"
     ]
    }
   ],
   "source": [
    "# Section 1: Feature Engineering & Model Tuning (Student Scores)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load student scores dataset\n",
    "student_df = pd.read_csv(\"C:\\\\Users\\\\saile\\\\Downloads\\\\student_scores.csv\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\\n\", student_df.isnull().sum())\n",
    "\n",
    "# Feature Engineering: Create Total Score and Average Score\n",
    "score_columns = [col for col in student_df.columns if col.lower() in ['math', 'science', 'english']]\n",
    "student_df['Total_Score'] = student_df[score_columns].sum(axis=1)\n",
    "student_df['Average_Score'] = student_df['Total_Score'] / len(score_columns)\n",
    "\n",
    "print(\"\\nUpdated Dataset:\\n\", student_df.head())\n",
    "\n",
    "# Define features and target\n",
    "features = score_columns + ['Total_Score', 'Average_Score']\n",
    "target_col = 'FinalGrade' if 'FinalGrade' in student_df.columns else student_df.columns[-1]\n",
    "X = student_df[features]\n",
    "y = student_df[target_col]\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Hyperparameter Tuning with GridSearchCV (Random Forest)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model and evaluation\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Optimized RMSE: {rmse:.2f}\")\n",
    "print(f\"Optimized R² Score: {r2:.2f}\")\n",
    "\n",
    "# Section 2: Fraud Detection with Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load fraud detection dataset\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\saile\\\\Downloads\\\\fraud_detection.csv\")\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "df = df.dropna()\n",
    "\n",
    "# Encode categorical variables\n",
    "le = LabelEncoder()\n",
    "df['Type_encoded'] = le.fit_transform(df['Type'])\n",
    "\n",
    "# Feature Engineering: Amount squared\n",
    "df['Amount_squared'] = df['Amount'] ** 2\n",
    "\n",
    "# Define features and target\n",
    "features = ['Amount', 'Type_encoded', 'Amount_squared']\n",
    "X = df[features]\n",
    "y = df['Is Fraud']\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")\n",
    "\n",
    "# Hyperparameter Tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_dt = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate Model Performance\n",
    "y_pred = best_dt.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "\n",
    "# Recommendations for improvement\n",
    "print('Recommendations:')\n",
    "print('- Try more advanced feature engineering (e.g., transaction frequency, time-based features).')\n",
    "print('- Use ensemble methods like Random Forest or boosting for better accuracy.')\n",
    "print('- Address class imbalance if present using SMOTE or class weights.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645de214-7d00-4e38-8706-b3bd743a2653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
